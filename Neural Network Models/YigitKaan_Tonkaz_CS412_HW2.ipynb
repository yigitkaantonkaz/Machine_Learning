{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xGUhi241MqG"
      },
      "source": [
        "# CS 412 Homework 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgQ50lDrqyI2"
      },
      "source": [
        "## Import Libraries\n",
        "The libraries used in this homework are already preinstalled in Google Colab. If you are working locally, make sure to create a virtual environment and install the required libraries there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxLzIUEa1GZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f099fe88-a7b1-40e5-bdd6-9b30814c3467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrC-jQzS-Pli"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ge7pX4yIW2j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a845d26f-ad2e-44b8-db96-de7ef24dcbe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qWmgoMgr56hpCEjJe0XQ-K46-yMpFhVS\n",
            "To: /content/imdb_dataset.csv\n",
            "100%|██████████| 66.2M/66.2M [00:00<00:00, 75.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'imdb_dataset.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "# Downloading data\n",
        "import gdown\n",
        "data_url = \"https://drive.google.com/uc?id=1qWmgoMgr56hpCEjJe0XQ-K46-yMpFhVS\"\n",
        "save_path = \"imdb_dataset.csv\"\n",
        "gdown.download(data_url, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EbbBMGUIrrr"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"imdb_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LNWT1YU-Mx-"
      },
      "source": [
        "## **1. Preproces text data** (30 pts)\n",
        "In this section, you have to preprocess the text data in order to convert it to a numerical representation that can be passed to machine learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy5DxN7xCHPa"
      },
      "source": [
        "### 1.1 **Remove HTML**\n",
        "Since these reviews were scraped from the internet, some of them still have some HTML tags (like \\<a> or \\<br>). These tags do not have any semantic meaning. Therefore, we have to remove them to avoid having noise in our data. Otherwise, the model will assume that these are words that have meanings. Here is one example of HTML tags in our data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nEDD7NCC4bx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "724619f6-c423-46ec-a34e-0f9d71ea48ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "df.loc[1, 'review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TOLq2eyJNKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d714f71-4d56-4cd1-c0e7-31e2e359e306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-73-00a77052a591>:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, \"html.parser\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n"
          ]
        }
      ],
      "source": [
        "# Remove HTML\n",
        "def remove_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "df['review'] = df['review'].apply(remove_html_tags)\n",
        "\n",
        "print(df.loc[1, 'review'])\n",
        "#df.to_csv('imdb_dataset_cleaned.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJHkc3ZvG3NA"
      },
      "source": [
        "### 1.2 **Converting text to lowercase**\n",
        "\n",
        "In text analysis, we usually convert text to lowercase to avoid having a very large vocabulary. For instance, if we do not convert the text to lowercase, the model will treat \"apple\", \"Apple\", and \"APPLE\" as completely different words. This way the number of words that the model has to know (which we call vocabulary) becomes very large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSztuMchJL_Y"
      },
      "outputs": [],
      "source": [
        "# Convert to lower case\n",
        "df['review'] = df['review'].str.lower()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wijyla-wDDlh"
      },
      "source": [
        "### 1.3 **Remove punctuation and special characters**\n",
        "Since our goal in this task is sentiment analysis, punctuations and special characters (like parantheses, percentage signs, etc.) do not change the sentiment of a movie review. Therefore we remove them to reduce the vocabulary size. One may argue that the exclamation (!) mark may affect the intensity of a sentiment. You have the choice to choose which punctuation marks to remove and which ones to keep. You have to remove some of them though to get the points for this part :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgkQeouQJK5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3b8fc2-0787-4236-b385-2b2b10572a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a wonderful little production the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done\n"
          ]
        }
      ],
      "source": [
        "# Remove punctuation and special characters\n",
        "import re\n",
        "\n",
        "def remove_punctuation_and_special_characters(text):\n",
        "    return re.sub(r'[^\\w\\s?!]', '', text)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_punctuation_and_special_characters)\n",
        "print(df.loc[1, 'review'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAmSnCegI4vG"
      },
      "source": [
        "### 1.4 **Tokenization**\n",
        "Now we want to convert each review into a sequence of words. This process is called tokenization. **Use `word_tokenize` from the `nltk.tokenize` module to tokenize each review**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJ-359NZJIq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb462137-5f48-45be-8b2d-c31b72d6fc0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized sentence: ['Hello', '!', 'this', 'is', 'a', 'test']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "test = 'Hello! this is a test'\n",
        "print(f\"Tokenized sentence: {word_tokenize(test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcUYM32DbuK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27bcc4cd-c0fd-46e0-c7cb-d9d9b78b47ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'wonderful', 'little', 'production', 'the', 'filming', 'technique', 'is', 'very', 'unassuming', 'very', 'oldtimebbc', 'fashion', 'and', 'gives', 'a', 'comforting', 'and', 'sometimes', 'discomforting', 'sense', 'of', 'realism', 'to', 'the', 'entire', 'piece', 'the', 'actors', 'are', 'extremely', 'well', 'chosen', 'michael', 'sheen', 'not', 'only', 'has', 'got', 'all', 'the', 'polari', 'but', 'he', 'has', 'all', 'the', 'voices', 'down', 'pat', 'too', '!', 'you', 'can', 'truly', 'see', 'the', 'seamless', 'editing', 'guided', 'by', 'the', 'references', 'to', 'williams', 'diary', 'entries', 'not', 'only', 'is', 'it', 'well', 'worth', 'the', 'watching', 'but', 'it', 'is', 'a', 'terrificly', 'written', 'and', 'performed', 'piece', 'a', 'masterful', 'production', 'about', 'one', 'of', 'the', 'great', 'masters', 'of', 'comedy', 'and', 'his', 'life', 'the', 'realism', 'really', 'comes', 'home', 'with', 'the', 'little', 'things', 'the', 'fantasy', 'of', 'the', 'guard', 'which', 'rather', 'than', 'use', 'the', 'traditional', 'dream', 'techniques', 'remains', 'solid', 'then', 'disappears', 'it', 'plays', 'on', 'our', 'knowledge', 'and', 'our', 'senses', 'particularly', 'with', 'the', 'scenes', 'concerning', 'orton', 'and', 'halliwell', 'and', 'the', 'sets', 'particularly', 'of', 'their', 'flat', 'with', 'halliwells', 'murals', 'decorating', 'every', 'surface', 'are', 'terribly', 'well', 'done']\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the review texts\n",
        "from nltk.tokenize import word_tokenize\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "df['review'] = df['review'].apply(tokenize_text)\n",
        "print(df.loc[1, 'review'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dogh5QLQJcSx"
      },
      "source": [
        "### 1.5 **Removing stop words**\n",
        "\n",
        "\n",
        "We also need to remove the stopwords (is, the, you, etc.) since they do not add to the meaning. Why? To reduce the vocabulary size 😃. **You can get a list of all stopwords from the nltk library**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TufKm5YsL8hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c37b41f9-cb07-4dee-ce2f-8944a38efac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['wonderful', 'little', 'production', 'filming', 'technique', 'unassuming', 'oldtimebbc', 'fashion', 'gives', 'comforting', 'sometimes', 'discomforting', 'sense', 'realism', 'entire', 'piece', 'actors', 'extremely', 'well', 'chosen', 'michael', 'sheen', 'got', 'polari', 'voices', 'pat', '!', 'truly', 'see', 'seamless', 'editing', 'guided', 'references', 'williams', 'diary', 'entries', 'well', 'worth', 'watching', 'terrificly', 'written', 'performed', 'piece', 'masterful', 'production', 'one', 'great', 'masters', 'comedy', 'life', 'realism', 'really', 'comes', 'home', 'little', 'things', 'fantasy', 'guard', 'rather', 'use', 'traditional', 'dream', 'techniques', 'remains', 'solid', 'disappears', 'plays', 'knowledge', 'senses', 'particularly', 'scenes', 'concerning', 'orton', 'halliwell', 'sets', 'particularly', 'flat', 'halliwells', 'murals', 'decorating', 'every', 'surface', 'terribly', 'well', 'done']\n"
          ]
        }
      ],
      "source": [
        "# Remove stop words\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return [token for token in tokens if token.lower() not in stop_words]\n",
        "\n",
        "df['review'] = df['review'].apply(remove_stopwords)\n",
        "print(df.loc[1, 'review'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqvJ6QUVON1B"
      },
      "source": [
        "### 1.6 **Stemming**\n",
        "\n",
        "Apply stemming using one of the `SnowballStemmer` stemmers in the nltk library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrbB6dtK-gZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf330bb5-a6ef-41f1-85a0-d4c0a9bc6fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['wonder', 'littl', 'product', 'film', 'techniqu', 'unassum', 'oldtimebbc', 'fashion', 'give', 'comfort', 'sometim', 'discomfort', 'sens', 'realism', 'entir', 'piec', 'actor', 'extrem', 'well', 'chosen', 'michael', 'sheen', 'got', 'polari', 'voic', 'pat', '!', 'truli', 'see', 'seamless', 'edit', 'guid', 'refer', 'william', 'diari', 'entri', 'well', 'worth', 'watch', 'terrif', 'written', 'perform', 'piec', 'master', 'product', 'one', 'great', 'master', 'comedi', 'life', 'realism', 'realli', 'come', 'home', 'littl', 'thing', 'fantasi', 'guard', 'rather', 'use', 'tradit', 'dream', 'techniqu', 'remain', 'solid', 'disappear', 'play', 'knowledg', 'sens', 'particular', 'scene', 'concern', 'orton', 'halliwel', 'set', 'particular', 'flat', 'halliwel', 'mural', 'decor', 'everi', 'surfac', 'terribl', 'well', 'done']\n"
          ]
        }
      ],
      "source": [
        "# Apply Stemming\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "def apply_stemming(tokens):\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "df['review'] = df['review'].apply(apply_stemming)\n",
        "print(df.loc[1, 'review'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nnGZFTqdbna"
      },
      "source": [
        "### 1.7 **Joining review text**\n",
        "Now that we have removed the stopwords and applied stemming on each word, we need to convert each review from a list of word to a space-separated string. The reason we do this is that the functions that are used to extract numerical representations from text expect the input to be a single string not a list of words.\n",
        "\n",
        "**Convert each review from a list of words to a space-separated string.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPfZK9fFeOXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1f906d-0b4f-428e-9ba1-171b53273a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wonder littl product film techniqu unassum oldtimebbc fashion give comfort sometim discomfort sens realism entir piec actor extrem well chosen michael sheen got polari voic pat ! truli see seamless edit guid refer william diari entri well worth watch terrif written perform piec master product one great master comedi life realism realli come home littl thing fantasi guard rather use tradit dream techniqu remain solid disappear play knowledg sens particular scene concern orton halliwel set particular flat halliwel mural decor everi surfac terribl well done\n"
          ]
        }
      ],
      "source": [
        "# Your solution\n",
        "def list_to_string(words_list):\n",
        "    return ' '.join(words_list)\n",
        "\n",
        "df['review'] = df['review'].apply(list_to_string)\n",
        "print(df.loc[1, 'review'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOTAoMoFq706"
      },
      "source": [
        "## 2. **Buidling Simple NN Models** (70 Pts)\n",
        "In this section, you will build neural network models to predict the sentiment of each review. You will build three models, where each of the models uses a different numerical representation of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlluZFZ7YmYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340e9fda-940c-4c04-c10f-9e9130dfbb70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Import all necessary libraries here\n",
        "!pip install tensorflow\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iada5kfkYtPr"
      },
      "source": [
        "### 2.1 **Data preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y4MmQQ3WRSM"
      },
      "source": [
        "#### 2.1.1 **Encoding labels**\n",
        "Encode the labels (\"positive\" and \"negative\") as 0 for \"negative\" and 1 for \"positive\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePwco1nbW7o8"
      },
      "outputs": [],
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
        "\n",
        "#print(df.loc[1,'review'])\n",
        "#print(df.loc[1,'sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK92SdrYWyrs"
      },
      "source": [
        "#### 2.1.2 **Splitting data**\n",
        "Split your data into train, validation, and test sets. You should use 80% of your data for training and 20% for testing. You should also use 20% of your training data for validation. **Set random_state to 42 to ensure consistent results.**\n",
        "\n",
        "Hint: You can pass parameters in Keras to use some of your data for validation while training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFskqoM2XV-I"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    df['review'], df['sentiment'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(\n",
        "    train_data, train_labels, test_size=0.25, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUEouGNLZiat"
      },
      "source": [
        "#### **Exploring vocabulary**\n",
        "Create a dictionary that maps each word in your training data to the number of times it occurs in the training data. The dictionary should have the following format:\n",
        "\n",
        "```\n",
        "vocab_count = {\n",
        "  \"word1\": 1,\n",
        "  \"word2\": 120,\n",
        "  ...\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrBcdP3maD53"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary for vocabulary count inn training data\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_data)\n",
        "vocab_count = dict(zip(vectorizer.get_feature_names_out(), X_train.sum(axis=0).tolist()[0]))\n",
        "vocab_count = {word: frequency for word, frequency in vocab_count.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_20IICeefsux",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "ab44677e-dab0-43c6-840f-e043db5935b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 126100\n",
            "Top 15 frequent words: movi, film, one, like, time, good, make, see, charact, get, watch, even, stori, would, realli\n",
            "Least frequent 15 words: namefor, nameh, namejim, nameno, namesbut, namenonono, nameord, nameorigin, namepro, nameprofess, namer, namerecognit, namerobert, namesa, laughingso\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Run this cell to explore the vocabulary\n",
        "import seaborn as sns\n",
        "count_arr = np.array(list(vocab_count.values()))\n",
        "vocab = np.array(list(vocab_count.keys()))\n",
        "\n",
        "# Sorting by frequency\n",
        "sort_idx = np.argsort(count_arr)[::-1]\n",
        "vocab = vocab[sort_idx]\n",
        "count_arr = count_arr[sort_idx]\n",
        "\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "print(f\"Top 15 frequent words: {', '.join(vocab[:15])}\")\n",
        "print(f\"Least frequent 15 words: {', '.join(vocab[-15:])}\")\n",
        "print()\n",
        "\n",
        "ax = sns.histplot(count_arr, log_scale=True, bins=100)\n",
        "ax.set_yscale('log')\n",
        "ax.set_xlabel('Number of word occurrences')\n",
        "ax.set_title(\"Histogram of vocabulary frequencies in training data\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YqsJq0Cgk_2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ArllJNd_RL8"
      },
      "source": [
        "### 2.2 **Bag of Words (BoW) model**\n",
        "Create a simple NN model that utilizes the Bag of Words representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlAe5IAzY7i3"
      },
      "source": [
        "#### 2.2.1 **Generate Bag of Words (BoW) representation**\n",
        "\n",
        "You can use the `CountVectorizer` class from `sklearn` to do this. Since your data is already preprocessed, set the `preprocessor` argument of `CountVectorizer` to pass a function that does nothing (`lambda x: x`). This way, `CountVectorizer` will not do any preprocessing on your data.\n",
        "\n",
        "Choose a reasonable value for the `max_features` argument. This argument determines how many words will be included in your vocabulary. For example, if your total vocabulary count is 100,000 and you set `max_features = 2,000`, `CountVectorizer` will only consider the **most frequent** 2,000 words in your vocabulary. The rest of the vocabulary will be ignored.\n",
        "\n",
        "* [CountVectorizer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvIioVluY4TA"
      },
      "outputs": [],
      "source": [
        "# Your solution\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "max_features = 3000 # Choose a value for max_features\n",
        "vectorizer = CountVectorizer(max_features=max_features, preprocessor=lambda x: x)\n",
        "\n",
        "# Fit the vectorizer to your train data\n",
        "vectorizer.fit(train_data)\n",
        "\n",
        "# Transform the train and test data\n",
        "train_bow = vectorizer.transform(train_data)\n",
        "train_bow_dense = train_bow.toarray()\n",
        "test_bow = vectorizer.transform(test_data)\n",
        "test_bow_dense = test_bow.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vlTK6pl0IXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe9f17b3-be71-487d-abb9-a3e43035c85d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 3000)\n"
          ]
        }
      ],
      "source": [
        "# The shape of the train data BoW representation should be\n",
        "# (Number of data points in training data x max_features)\n",
        "print(train_bow.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsnVbn50ZTs-"
      },
      "source": [
        "#### 2.2.2 **Train a neural network on BoW data**\n",
        "Use a small neural network to predict the sentiment of reviews from the BoW representation of the reviews. Use the keras library for this task.\n",
        "\n",
        "**Notes**:\n",
        "* Your neural network should have **maximum two hidden layers**.\n",
        "* Train for **10 epochs or less**\n",
        "* Choose any method you find suitable to **avoid overfitting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut5c1ivakTvc"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5H-Wsu60jXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9beefe-47b6-4374-f257-0b61947bdf3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 64)                192064    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 192129 (750.50 KB)\n",
            "Trainable params: 192129 (750.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "750/750 [==============================] - 8s 8ms/step - loss: 0.3782 - accuracy: 0.8400 - val_loss: 0.3131 - val_accuracy: 0.8748\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.2637 - accuracy: 0.8957 - val_loss: 0.3066 - val_accuracy: 0.8722\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.2193 - accuracy: 0.9155 - val_loss: 0.3159 - val_accuracy: 0.8723\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.1870 - accuracy: 0.9295 - val_loss: 0.3254 - val_accuracy: 0.8693\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1546 - accuracy: 0.9447 - val_loss: 0.3538 - val_accuracy: 0.8692\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.1276 - accuracy: 0.9560 - val_loss: 0.3724 - val_accuracy: 0.8692\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1131 - accuracy: 0.9622 - val_loss: 0.3969 - val_accuracy: 0.8655\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.0966 - accuracy: 0.9667 - val_loss: 0.4221 - val_accuracy: 0.8652\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.0784 - accuracy: 0.9726 - val_loss: 0.4650 - val_accuracy: 0.8638\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.0683 - accuracy: 0.9772 - val_loss: 0.4821 - val_accuracy: 0.8635\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ae564307b20>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "# Build the model\n",
        "from keras.layers import Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=max_features))\n",
        "model.add(Dropout(0.5)) #to avoid overfitting\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Show model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "# When fitting the model, set validation_split=0.20 to use 20% of the train data\n",
        "# for validation\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "model.fit(train_bow_dense, train_labels, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bQfHwju1vx_"
      },
      "source": [
        "#### 2.2.3 **Evaluate on test dataset**\n",
        "After choosing the suitable model hyperparameters and training a model in the previous step, evaluate your model on the test set. Choose the metrics you find suitable for evauluating this model.\n",
        "\n",
        "**Note**: Evaluation on the test dataset should only be done once. Updating your model iteratively until you get a good performance on the test dataset is not a good practice and will result in overfitting on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_6rzD-y1qXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86630eac-96b9-4033-9af4-9f87e8a0177a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "Test Accuracy: 0.8754\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "from sklearn.metrics import accuracy_score\n",
        "pred = model.predict(test_bow_dense)\n",
        "pred_binary = (pred > 0.5).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, pred_binary)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFYph9dm_VOr"
      },
      "source": [
        "### 2.3 **TF-IDF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUn_mGiMZLuq"
      },
      "source": [
        "Create a simple NN model that utilizes the TF-IDF representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9pwr-uZ3Ik1"
      },
      "source": [
        "#### 2.3.1 **Generate TF-IDF representation**\n",
        "\n",
        "You can use the `TfidfVectorizer` class from `sklearn` to do this. Since your data is already preprocessed, set the `preprocessor` argument of `TfidfVectorizer` to pass a function that does nothing (`lambda x: x`). This way, `TfidfVectorizer` will not do any preprocessing on your data.\n",
        "\n",
        "Choose a reasonable value for the `max_features` argument.\n",
        "\n",
        "* [TfidfVectorizer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEQa7Y4I_W_8"
      },
      "outputs": [],
      "source": [
        "# Your solution\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "max_features = 3000\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=max_features, preprocessor=lambda x: x)\n",
        "\n",
        "# Fit the vectorizer to your train data\n",
        "vectorizer.fit(train_data)\n",
        "\n",
        "# Transform the train and test data\n",
        "train_tfidf = vectorizer.transform(train_data)\n",
        "train_tfidf_dense = train_tfidf.toarray()\n",
        "test_tfidf = vectorizer.transform(test_data)\n",
        "test_tfidf_dense = test_tfidf.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TU6aX5N40Mx"
      },
      "source": [
        "#### 2.3.2 **Train a neural network on TF-IDF data**\n",
        "Use a small neural network to predict the sentiment of reviews from the TF-IDF representation of the reviews. Use the keras library for this task. **You can use the same neural network structure form the BoW model.**\n",
        "\n",
        "**Notes**:\n",
        "* Your neural network should have **maximum two hidden layers**.\n",
        "* Train for **10 epochs or less**\n",
        "* Choose any method you find suitable to **avoid overfitting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfVf7osX49KU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365429be-6212-4a7b-dd6f-3c3bfb3b7a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 64)                192064    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 192129 (750.50 KB)\n",
            "Trainable params: 192129 (750.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3809 - accuracy: 0.8411 - val_loss: 0.3143 - val_accuracy: 0.8700\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.2590 - accuracy: 0.8989 - val_loss: 0.3053 - val_accuracy: 0.8662\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2167 - accuracy: 0.9168 - val_loss: 0.3114 - val_accuracy: 0.8708\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.1810 - accuracy: 0.9315 - val_loss: 0.3312 - val_accuracy: 0.8683\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.1493 - accuracy: 0.9472 - val_loss: 0.3531 - val_accuracy: 0.8707\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.1260 - accuracy: 0.9560 - val_loss: 0.3762 - val_accuracy: 0.8667\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.1085 - accuracy: 0.9625 - val_loss: 0.3972 - val_accuracy: 0.8642\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.0928 - accuracy: 0.9676 - val_loss: 0.4192 - val_accuracy: 0.8643\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.0761 - accuracy: 0.9745 - val_loss: 0.4393 - val_accuracy: 0.8627\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.0677 - accuracy: 0.9768 - val_loss: 0.4936 - val_accuracy: 0.8647\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ae564360d30>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "# Build the model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=max_features))\n",
        "model.add(Dropout(0.5)) #to avoid overfitting\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Show model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "# When fitting the model, set validation_split=0.20 to use 20% of the train data\n",
        "# for validation\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "model.fit(train_tfidf_dense, train_labels, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hPry9cx5FFb"
      },
      "source": [
        "#### 2.2.3 **Evaluate on test dataset**\n",
        "After choosing the suitable model hyperparameters and training a model in the previous step, evaluate your model on the test set. Choose the metrics you find suitable for evauluating this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3W9Dh7xIip3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91748865-5ff5-4c7d-fa1b-0a216dc39a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "Test Accuracy: 0.875\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "from sklearn.metrics import accuracy_score\n",
        "pred_2 = model.predict(test_tfidf_dense)\n",
        "pred_binary_2 = (pred_2 > 0.5).astype(int)\n",
        "\n",
        "accuracy_2 = accuracy_score(test_labels, pred_binary_2)\n",
        "print(f'Test Accuracy: {accuracy_2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZj46dBC_XnP"
      },
      "source": [
        "### 2.4 **Word2Vec**\n",
        "In this section, you will use Word2Vec representations to train a simple neural network to predict the sentiments of reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX6AhwZB5ltk"
      },
      "source": [
        "#### 2.4.1 **Preliminary About Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxil2TcVCJEm"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxehiNoc6EPr"
      },
      "source": [
        "The following cell will load a pretrained Word2Vec model. This is a model trained on a large corpus of data to produce meaningful representations of words as vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsjavca9_auI"
      },
      "outputs": [],
      "source": [
        "# Loading pretrained Word2Vec model (Word embeddings)\n",
        "model_name = \"glove-wiki-gigaword-100\"\n",
        "word_to_vec = gensim.downloader.load(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNxPVPUz7G7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83417d2f-0052-4731-9c18-a026489c378d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.30817  ,  0.30938  ,  0.52803  , -0.92543  , -0.73671  ,\n",
              "        0.63475  ,  0.44197  ,  0.10262  , -0.09142  , -0.56607  ,\n",
              "       -0.5327   ,  0.2013   ,  0.7704   , -0.13983  ,  0.13727  ,\n",
              "        1.1128   ,  0.89301  , -0.17869  , -0.0019722,  0.57289  ,\n",
              "        0.59479  ,  0.50428  , -0.28991  , -1.3491   ,  0.42756  ,\n",
              "        1.2748   , -1.1613   , -0.41084  ,  0.042804 ,  0.54866  ,\n",
              "        0.18897  ,  0.3759   ,  0.58035  ,  0.66975  ,  0.81156  ,\n",
              "        0.93864  , -0.51005  , -0.070079 ,  0.82819  , -0.35346  ,\n",
              "        0.21086  , -0.24412  , -0.16554  , -0.78358  , -0.48482  ,\n",
              "        0.38968  , -0.86356  , -0.016391 ,  0.31984  , -0.49246  ,\n",
              "       -0.069363 ,  0.018869 , -0.098286 ,  1.3126   , -0.12116  ,\n",
              "       -1.2399   , -0.091429 ,  0.35294  ,  0.64645  ,  0.089642 ,\n",
              "        0.70294  ,  1.1244   ,  0.38639  ,  0.52084  ,  0.98787  ,\n",
              "        0.79952  , -0.34625  ,  0.14095  ,  0.80167  ,  0.20987  ,\n",
              "       -0.86007  , -0.15308  ,  0.074523 ,  0.40816  ,  0.019208 ,\n",
              "        0.51587  , -0.34428  , -0.24525  , -0.77984  ,  0.27425  ,\n",
              "        0.22418  ,  0.20164  ,  0.017431 , -0.014697 , -1.0235   ,\n",
              "       -0.39695  , -0.0056188,  0.30569  ,  0.31748  ,  0.021404 ,\n",
              "        0.11837  , -0.11319  ,  0.42456  ,  0.53405  , -0.16717  ,\n",
              "       -0.27185  , -0.6255   ,  0.12883  ,  0.62529  , -0.52086  ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "# Getting the representation of a word\n",
        "dog = word_to_vec[\"dog\"]\n",
        "dog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me2Q_Ave6U1F"
      },
      "source": [
        "These representations are meaningful in a sense that words that have similar meanings are closer to each other. In general, when dealing with vector representations, we use **cosine similarity** to see how similar two vectors are. it returns a value between -1 and +1, the higher the value the more similar two vectors are.\n",
        "\n",
        "Notice in the example below that **car** is more similar to **vehicle** than **cat**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNkRtwBr6xjR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af2cd3c-d740-486a-be0a-6144d008c036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between car and cat: [[0.31097823]]\n",
            "Similarity between car and vehicle: [[0.86308384]]\n"
          ]
        }
      ],
      "source": [
        "from  sklearn.metrics.pairwise import cosine_similarity\n",
        "car = word_to_vec[\"car\"].reshape(1, -1) # Reshaping because cosine_similarity function requires a 2D array\n",
        "cat = word_to_vec[\"cat\"].reshape(1, -1)\n",
        "vehicle = word_to_vec[\"vehicle\"].reshape(1, -1)\n",
        "\n",
        "print(f\"Similarity between car and cat: {cosine_similarity(car, cat)}\")\n",
        "print(f\"Similarity between car and vehicle: {cosine_similarity(car, vehicle)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLS-06oTBMY-"
      },
      "source": [
        "#### 2.4.2 **Use pretrained Word2Vec model**\n",
        "First, you will try to use the pretrained Word2Vec model to generate representations for each review and use the representation to train a neural network.\n",
        "\n",
        "Remember that we are trying to classify movie reviews, which have can have any number of words. Word2Vec returns a vector representation for each word. Therefore, you have to find a way to create a **fixed-sized representation** for the whole review. Fixed-size means that the vector representation of each review should have the same size regardless of the length of the review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RO53y0h4F8b"
      },
      "outputs": [],
      "source": [
        "# Your solution\n",
        "# This function should convert each review to a fixed-sized vectoriz representation\n",
        "def vectorize(review):\n",
        "  # WRITE YOUR CODE HERE\n",
        "  words = word_tokenize(review.lower())\n",
        "  vectors = [word_to_vec[word] for word in words if word in word_to_vec]\n",
        "\n",
        "  if vectors:\n",
        "    review_vector = np.mean(vectors, axis=0)\n",
        "  else:\n",
        "    review_vector = np.zeros(word_to_vec.vector_size)\n",
        "  return review_vector\n",
        "\n",
        "# Applying your function to convert the train and test reviews to vector representations\n",
        "# WRITE YOUR CODE HERE\n",
        "train_word2vec = np.vstack([vectorize(review) for review in train_data])\n",
        "test_word2vec = np.vstack([vectorize(review) for review in test_data])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6nG9NJ8HzgW"
      },
      "source": [
        "Train a neural network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbLkFZXlIYYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2844f8d2-f621-4e4d-ae30-9a415af12b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 64)                6464      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6529 (25.50 KB)\n",
            "Trainable params: 6529 (25.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "750/750 [==============================] - 3s 3ms/step - loss: 0.5686 - accuracy: 0.7143 - val_loss: 0.5279 - val_accuracy: 0.7393\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.5107 - accuracy: 0.7548 - val_loss: 0.5168 - val_accuracy: 0.7483\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.5009 - accuracy: 0.7605 - val_loss: 0.5010 - val_accuracy: 0.7570\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4978 - accuracy: 0.7618 - val_loss: 0.4981 - val_accuracy: 0.7572\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4945 - accuracy: 0.7644 - val_loss: 0.4939 - val_accuracy: 0.7657\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4915 - accuracy: 0.7662 - val_loss: 0.4915 - val_accuracy: 0.7657\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4898 - accuracy: 0.7663 - val_loss: 0.4979 - val_accuracy: 0.7590\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4882 - accuracy: 0.7664 - val_loss: 0.4909 - val_accuracy: 0.7653\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4845 - accuracy: 0.7695 - val_loss: 0.4889 - val_accuracy: 0.7663\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4830 - accuracy: 0.7705 - val_loss: 0.4952 - val_accuracy: 0.7632\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ae57f6c9ff0>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "# Build the model\n",
        "num_features = word_to_vec.vector_size\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=num_features))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Show model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "# When fitting the model, set validation_split=0.20 to use 20% of the train data\n",
        "# for validation\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "model.fit(train_word2vec, train_labels, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj8W0JH0IZyM"
      },
      "source": [
        "Evaluate the model on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa0a8PcdIdnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3f595a-da84-4f53-99c1-70457461b681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step\n",
            "Test Accuracy: 0.7658\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the Model\n",
        "pred_3 = model.predict(test_word2vec)\n",
        "pred_binary_3 = (pred_3 > 0.5).astype(int)\n",
        "\n",
        "accuracy_3 = accuracy_score(test_labels, pred_binary_3)\n",
        "print(f'Test Accuracy: {accuracy_3}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIdPN7jwIuB_"
      },
      "source": [
        "#### 2.4.3 **Train your own Word2Vec model**\n",
        "In cases where we have enough data, training a new Word2Vec model may provide better results than using a pretrained one. Here, you will train your own Word2Vec model using the training data and then use it to create vector representations for the reviews.\n",
        "\n",
        "You can change the hyperparameters to train your Word2Vec model:\n",
        "* **vector_size**: The length of the vector that will be used to represent words.\n",
        "* **window**: The window sized used in the Word2Vec training\n",
        "* **min_count**: Minimum number of occurunces for a word to be included in the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbyDteDyI6wM"
      },
      "outputs": [],
      "source": [
        "# Converting sentences to list of words\n",
        "sentences = [sentence.split() for sentence in train_data]\n",
        "\n",
        "# Training model\n",
        "vector_size = 100\n",
        "window = 5\n",
        "min_count = 1\n",
        "\n",
        "w2v_model = Word2Vec(\n",
        "    sentences,\n",
        "    vector_size=vector_size,\n",
        "    window=window,\n",
        "    min_count=min_count,\n",
        "    workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRtjznn9Jd_C"
      },
      "source": [
        "Apply the same function you created above to create vector representations for the reviews from your trained Word2Vec model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZXc1G6HJ1lz"
      },
      "outputs": [],
      "source": [
        "# Your solution\n",
        "# This function should convert each review to a fixed-sized vectoriz representation\n",
        "def vectorize(review):\n",
        "  words = word_tokenize(review.lower())\n",
        "  vectors = [w2v_model.wv[word] for word in words if word in w2v_model.wv.key_to_index]\n",
        "\n",
        "  if vectors:\n",
        "    review_vector = np.mean(vectors, axis=0)\n",
        "  else:\n",
        "    review_vector = np.zeros(w2v_model.vector_size)\n",
        "  return review_vector\n",
        "\n",
        "# Applying your function to convert the train and test reviews to vector representations\n",
        "# WRITE YOUR CODE HERE\n",
        "train_w2v = np.vstack([vectorize(review) for review in train_data])\n",
        "test_w2v = np.vstack([vectorize(review) for review in test_data])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4bnRmZKXO7q"
      },
      "source": [
        "Train a neural network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHxZvwcQXaXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91fe0f63-c50b-4fec-938c-e0cbd3e68995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 64)                6464      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6529 (25.50 KB)\n",
            "Trainable params: 6529 (25.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "750/750 [==============================] - 4s 4ms/step - loss: 0.4141 - accuracy: 0.8153 - val_loss: 0.3819 - val_accuracy: 0.8285\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3643 - accuracy: 0.8403 - val_loss: 0.3708 - val_accuracy: 0.8385\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3565 - accuracy: 0.8461 - val_loss: 0.3690 - val_accuracy: 0.8360\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3500 - accuracy: 0.8480 - val_loss: 0.3644 - val_accuracy: 0.8397\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3479 - accuracy: 0.8489 - val_loss: 0.3614 - val_accuracy: 0.8420\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3470 - accuracy: 0.8479 - val_loss: 0.3650 - val_accuracy: 0.8375\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3437 - accuracy: 0.8496 - val_loss: 0.3583 - val_accuracy: 0.8460\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3415 - accuracy: 0.8515 - val_loss: 0.3573 - val_accuracy: 0.8447\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3388 - accuracy: 0.8520 - val_loss: 0.3548 - val_accuracy: 0.8462\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3371 - accuracy: 0.8536 - val_loss: 0.3547 - val_accuracy: 0.8465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ae5846fabf0>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "# Build the model\n",
        "num_features = w2v_model.vector_size\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=num_features))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "# WRITE YOUR CODE HERE\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Show model summary\n",
        "# WRITE YOUR CODE HERE\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "# When fitting the model, set validation_split=0.20 to use 20% of the train data\n",
        "# for validation\n",
        "# WRITE YOUR CODE HERE\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "model.fit(train_w2v, train_labels, epochs=epochs, batch_size=batch_size, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86rLvA85XeoI"
      },
      "source": [
        "Evaluate the model on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwANruikXedY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3f7360-48c3-41ba-a436-d24f2a966ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step\n",
            "Test Accuracy: 0.8439\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the Model\n",
        "pred_4 = model.predict(test_w2v)\n",
        "pred_binary_4 = (pred_4 > 0.5).astype(int)\n",
        "\n",
        "accuracy_4 = accuracy_score(test_labels, pred_binary_4)\n",
        "print(f'Test Accuracy: {accuracy_4}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}